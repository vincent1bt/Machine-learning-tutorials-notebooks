{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TreeFace.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNGCzi9IpDQ5",
        "colab_type": "code",
        "outputId": "0782126e-51ce-4e63-b635-31439aad71c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbiXpKDsr92L",
        "colab_type": "code",
        "outputId": "f644ab96-17db-4f4e-97d8-b4f345099b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVgjYR5dsbh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g7Bk1cwARI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KovJlxPYo8UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqsg0dbq2CeF",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2hevxnp2EGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initializer = tf.random_normal_initializer(0., 0.02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdqQpuQ8u3Yy",
        "colab_type": "text"
      },
      "source": [
        "### CRU Node"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ySwjuUnR8K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRU(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(CRU, self).__init__()\n",
        "\n",
        "    self.conv1 = layers.Conv2D(40, (3, 3), strides=1, padding='SAME', kernel_initializer=initializer, use_bias=False)\n",
        "    self.batch1 = tfa.layers.GroupNormalization(groups=2, axis=3)\n",
        "\n",
        "    self.conv2 = layers.Conv2D(40, (3, 3), strides=1, padding='SAME', kernel_initializer=initializer, use_bias=False)\n",
        "    self.batch2 = tfa.layers.GroupNormalization(groups=2, axis=3)\n",
        "\n",
        "    self.conv3 = layers.Conv2D(40, (3, 3), strides=1, padding='SAME', kernel_initializer=initializer, use_bias=False)\n",
        "    self.batch3 = tfa.layers.GroupNormalization(groups=2, axis=3)\n",
        "  \n",
        "  def call(self, x, pooling=True):\n",
        "    model_1 = self.conv1(x)\n",
        "    model_1 = self.batch1(model_1)\n",
        "    model_1 = layers.ReLU()(model_1)\n",
        "\n",
        "    model_1 = x + model_1\n",
        "\n",
        "    model_2 = self.conv2(model_1)\n",
        "    model_2 = self.batch2(model_2)\n",
        "    model_2 = layers.ReLU()(model_2)\n",
        "\n",
        "    model_2 = model_1 + model_2\n",
        "\n",
        "    model_3 = self.conv3(model_1)\n",
        "    model_3 = self.batch3(model_2)\n",
        "    model_3 = layers.ReLU()(model_2)\n",
        "\n",
        "    model = model_3 + model_2\n",
        "\n",
        "    if pooling:\n",
        "      model = layers.MaxPool2D()(model)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYp5oKq-u6G_",
        "colab_type": "text"
      },
      "source": [
        "### Projection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL6qIUrBe5fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProjectionLayer(tf.keras.Model):\n",
        "  def __init__(self, layer_index, input_dim=5120):\n",
        "    super(ProjectionLayer, self).__init__()\n",
        "    self.v = tf.Variable(initial_value=initializer(shape=(input_dim, 1), dtype='float32'), trainable=True, name=\"v_{}\".format(layer_index))\n",
        "  \n",
        "  def call(self, compressed_x):\n",
        "    unit_v = self.v / (tf.norm(self.v) + 1e-8)\n",
        "    projection_route = tf.matmul(compressed_x, unit_v)\n",
        "\n",
        "    return projection_route, unit_v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_y_nAeZu8Oy",
        "colab_type": "text"
      },
      "source": [
        "### TRU Node"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajm6kMM6k883",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TRU(tf.keras.Model):\n",
        "  def __init__(self, filters=20, size=16):\n",
        "    super(TRU, self).__init__()\n",
        "\n",
        "    self.conv = layers.Conv2D(filters, (1, 1), strides=1, padding='SAME', kernel_initializer=initializer)\n",
        "\n",
        "    self.resize = layers.Lambda(lambda layer: tf.image.resize( \n",
        "      layer, \n",
        "      (size, size), \n",
        "      method=tf.image.ResizeMethod.BILINEAR\n",
        "    ))\n",
        "\n",
        "    self.reshape = layers.Reshape((size * size * filters,))\n",
        "    self.batch = layers.BatchNormalization(scale=False)\n",
        "  \n",
        "  def call(self, x):\n",
        "    model = self.conv(x)\n",
        "    model = self.resize(model)\n",
        "    model = self.reshape(model)\n",
        "    model = self.batch(model)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDwFuwCF7FH9",
        "colab_type": "text"
      },
      "source": [
        "### SFL Node"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv4N8BLTmFXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SFL(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(SFL, self).__init__()\n",
        "\n",
        "    self.conv1 = layers.Conv2D(1, (1, 1), activation=\"sigmoid\", kernel_initializer=initializer)\n",
        "\n",
        "    self.conv2 = layers.Conv2D(40, (3,3), kernel_initializer=initializer)\n",
        "    self.conv3 = layers.Conv2D(40, (3,3), kernel_initializer=initializer)\n",
        "    self.flat = layers.Flatten()\n",
        "\n",
        "    self.dense1 = layers.Dense(500, kernel_initializer=initializer)\n",
        "    self.dense2 = layers.Dense(1, activation=\"sigmoid\", kernel_initializer=initializer)\n",
        "  \n",
        "  def call(self, x):\n",
        "    mask = self.conv1(x)\n",
        "\n",
        "    classification = self.conv2(x)\n",
        "    classification = self.conv3(classification)\n",
        "    classification = self.flat(classification)\n",
        "\n",
        "    classification = self.dense1(classification)\n",
        "    classification = self.dense2(classification)\n",
        "\n",
        "    return classification, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2vinddet2bA",
        "colab_type": "text"
      },
      "source": [
        "### Unsupervised loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ttCK8vPt6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 1e-3\n",
        "beta = 1e-2\n",
        "\n",
        "a3 = 2.0\n",
        "a4 = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC24yZ4Mt5cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_tru_loss(spoof_x, not_x, unit_v, training):\n",
        "  loss = 0.0\n",
        "  if training and tf.shape(spoof_x)[0] > 0:\n",
        "    transpose_unit_v = tf.transpose(unit_v, [1, 0])\n",
        "    covariance_matrix = tf.matmul(spoof_x, spoof_x, transpose_a=True)\n",
        "    trace = tf.linalg.trace(covariance_matrix)\n",
        "\n",
        "    eigenvalue = tf.matmul(tf.matmul(transpose_unit_v, covariance_matrix), unit_v)\n",
        "\n",
        "    route_loss = tf.exp(-alpha * eigenvalue) + beta * trace\n",
        "\n",
        "    spoof_x_loss = -tf.reduce_mean(tf.square(tf.matmul(spoof_x, unit_v)))\n",
        "    not_x_loss = tf.reduce_mean(tf.square(tf.matmul(not_x, unit_v)))\n",
        "\n",
        "    unique_loss = spoof_x_loss + not_x_loss\n",
        "\n",
        "    loss = (a3 * route_loss) + (a4 * unique_loss)\n",
        "\n",
        "  return loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IVCvdbYWZg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DTN(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(DTN, self).__init__()\n",
        "\n",
        "    self.input_layer = layers.Conv2D(40, (1, 1))\n",
        "\n",
        "    self.cru_1 = CRU()\n",
        "    \n",
        "    self.cru_2 = CRU()\n",
        "    self.cru_3 = CRU()\n",
        "\n",
        "    self.cru_4 = CRU()\n",
        "    self.cru_5 = CRU()\n",
        "    self.cru_6 = CRU()\n",
        "    self.cru_7 = CRU()\n",
        "    \n",
        "    self.cru_8 = CRU()\n",
        "    self.cru_9 = CRU()\n",
        "    self.cru_10 = CRU()\n",
        "    self.cru_11 = CRU()\n",
        "    self.cru_12 = CRU()\n",
        "    self.cru_13 = CRU()\n",
        "    self.cru_14 = CRU()\n",
        "    self.cru_15 = CRU()\n",
        "\n",
        "    self.tru_1 = TRU(filters=10, size=32)\n",
        "    \n",
        "    self.tru_2 = TRU()\n",
        "    self.tru_3 = TRU()\n",
        "\n",
        "    self.tru_4 = TRU()\n",
        "    self.tru_5 = TRU()\n",
        "    self.tru_6 = TRU()\n",
        "    self.tru_7 = TRU()\n",
        "\n",
        "    self.sfl_1 = SFL()\n",
        "    self.sfl_2 = SFL()\n",
        "    self.sfl_3 = SFL()\n",
        "    self.sfl_4 = SFL()\n",
        "    self.sfl_5 = SFL()\n",
        "    self.sfl_6 = SFL()\n",
        "    self.sfl_7 = SFL()\n",
        "    self.sfl_8 = SFL()\n",
        "\n",
        "    self.projection_root_layer = ProjectionLayer(layer_index=1, input_dim=10240)\n",
        "    \n",
        "    self.projection_left_1_1_layer = ProjectionLayer(layer_index=2, input_dim=5120)\n",
        "    self.projection_right_1_2_layer = ProjectionLayer(layer_index=3, input_dim=5120)\n",
        "\n",
        "    self.projection_left_2_1_layer = ProjectionLayer(layer_index=4, input_dim=5120)\n",
        "    self.projection_right_2_2_layer = ProjectionLayer(layer_index=5, input_dim=5120)\n",
        "    self.projection_left_2_3_layer = ProjectionLayer(layer_index=6, input_dim=5120)\n",
        "    self.projection_right_2_4_layer = ProjectionLayer(layer_index=7, input_dim=5120)\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, labels, training=True):\n",
        "    input_layer = self.input_layer(x)\n",
        "\n",
        "    # Root Level\n",
        "    cru_root = self.cru_1(input_layer)\n",
        "    tru_root = self.tru_1(cru_root)\n",
        "    projection_root, root_unit_v = self.projection_root_layer(tru_root)\n",
        "\n",
        "    # Root Masking\n",
        "\n",
        "    if training:\n",
        "      spoof_mask = tf.where(labels == 1, x=True, y=False)\n",
        "      live_mask = tf.where(labels == 0, x=True, y=False)\n",
        "\n",
        "      right_data = tf.boolean_mask(tru_root, spoof_mask)\n",
        "      left_data = tf.boolean_mask(tru_root, live_mask)\n",
        "    else:\n",
        "      right_data = np.array([])\n",
        "      left_data = np.array([])\n",
        "\n",
        "    unsupervised_root_loss = compute_tru_loss(right_data, left_data, root_unit_v, training)\n",
        "\n",
        "    # Level 1 ================================================================================================================================\n",
        "\n",
        "    # Block 1, 2 Create masks\n",
        "\n",
        "    right_mask = tf.where(projection_root >= 0, x=True, y=False)\n",
        "    left_mask = tf.where(projection_root < 0, x=True, y=False)\n",
        "\n",
        "    # Block 1 (left node)\n",
        "    cru_left_1_1 = self.cru_2(cru_root)\n",
        "    tru_left_1_1 = self.tru_2(cru_left_1_1)\n",
        "    projection_left_1_1, left_1_1_unit_v = self.projection_left_1_1_layer(tru_left_1_1)\n",
        "\n",
        "    # Block 1 Masking\n",
        "\n",
        "    right_data = tf.boolean_mask(tru_left_1_1, tf.squeeze(right_mask))\n",
        "    left_data = tf.boolean_mask(tru_left_1_1, tf.squeeze(left_mask))\n",
        "\n",
        "    unsupervised_left_1_1_loss = compute_tru_loss(left_data, right_data, left_1_1_unit_v, training)\n",
        "\n",
        "    # Block 2 (right node)\n",
        "\n",
        "    cru_right_1_2 = self.cru_3(cru_root)\n",
        "    tru_right_1_2 = self.tru_3(cru_right_1_2)\n",
        "    projection_right_1_2, right_1_2_unit_v = self.projection_right_1_2_layer(tru_right_1_2)\n",
        "\n",
        "    # Block 2 Masking\n",
        "\n",
        "    right_data = tf.boolean_mask(tru_right_1_2, tf.squeeze(right_mask))\n",
        "    left_data = tf.boolean_mask(tru_right_1_2, tf.squeeze(left_mask))\n",
        "\n",
        "    unsupervised_right_1_2_loss = compute_tru_loss(right_data, left_data, right_1_2_unit_v, training)\n",
        "\n",
        "    # Level 2 ===============================================================================================================================\n",
        "\n",
        "    # Block 1, 2 Create masks\n",
        "\n",
        "    right_mask = tf.where(projection_left_1_1 >= 0, x=True, y=False)\n",
        "    left_mask = tf.where(projection_left_1_1 < 0, x=True, y=False)\n",
        "\n",
        "    # Block 1 (left node)\n",
        "    cru_left_2_1 = self.cru_4(cru_left_1_1)\n",
        "    tru_left_2_1 = self.tru_4(cru_left_2_1)\n",
        "    projection_left_2_1, left_2_1_unit_v = self.projection_left_2_1_layer(tru_left_2_1)\n",
        "\n",
        "    # Block 1 Masking\n",
        "\n",
        "    right_data = tf.boolean_mask(tru_left_2_1, tf.squeeze(right_mask))\n",
        "    left_data = tf.boolean_mask(tru_left_2_1, tf.squeeze(left_mask))\n",
        "\n",
        "    unsupervised_left_2_1_loss = compute_tru_loss(left_data, right_data, left_2_1_unit_v, training)\n",
        "\n",
        "    # Block 2 (right node)\n",
        "\n",
        "    cru_right_2_2 = self.cru_5(cru_left_1_1)\n",
        "    tru_right_2_2 = self.tru_5(cru_right_2_2)\n",
        "    projection_right_2_2, right_2_2_unit_v = self.projection_right_2_2_layer(tru_right_2_2)\n",
        "\n",
        "    # Block 2 Masking\n",
        "    right_data = tf.boolean_mask(tru_right_2_2, tf.squeeze(right_mask))\n",
        "    left_data = tf.boolean_mask(tru_right_2_2, tf.squeeze(left_mask))\n",
        "\n",
        "    unsupervised_right_2_2_loss = compute_tru_loss(right_data, left_data, right_2_2_unit_v, training)\n",
        "\n",
        "    # Block 3, 4 Create masks\n",
        "\n",
        "    right_mask = tf.where(projection_right_1_2 >= 0, x=True, y=False)\n",
        "    left_mask = tf.where(projection_right_1_2 < 0, x=True, y=False)\n",
        "\n",
        "    # Block 3 (left node)\n",
        "    cru_left_2_3 = self.cru_6(cru_right_1_2)\n",
        "    tru_left_2_3 = self.tru_6(cru_left_2_3)\n",
        "    projection_left_2_3, left_2_3_unit_v = self.projection_left_2_3_layer(tru_left_2_3)\n",
        "\n",
        "    # Block 3 Masking\n",
        "\n",
        "    right_data = tf.boolean_mask(tru_left_2_3, tf.squeeze(right_mask))\n",
        "    left_data = tf.boolean_mask(tru_left_2_3, tf.squeeze(left_mask))\n",
        "\n",
        "    unsupervised_left_2_3_loss = compute_tru_loss(left_data, right_data, left_2_3_unit_v, training)\n",
        "\n",
        "    # Block 4 (right node)\n",
        "\n",
        "    cru_right_2_4 = self.cru_7(cru_right_1_2)\n",
        "    tru_right_2_4 = self.tru_7(cru_right_2_4)\n",
        "    projection_right_2_4, right_2_4_unit_v = self.projection_right_2_4_layer(tru_right_2_4)\n",
        "\n",
        "    # Block 4 Masking\n",
        "\n",
        "    right_data = tf.boolean_mask(tru_right_2_4, tf.squeeze(right_mask))\n",
        "    left_data = tf.boolean_mask(tru_right_2_4, tf.squeeze(left_mask))\n",
        "\n",
        "    unsupervised_right_2_4_loss = compute_tru_loss(right_data, left_data, right_2_4_unit_v, training)\n",
        "\n",
        "    # Level 3 ===============================================================================================================================\n",
        "\n",
        "    # Block 1 (left node)\n",
        "\n",
        "    cru_left_3_1 = self.cru_8(cru_left_2_1, pooling=False)\n",
        "    class_left_3_1, map_left_3_1 = self.sfl_1(cru_left_3_1)\n",
        "\n",
        "    mask_left_3_1 = tf.where(projection_left_2_1 < 0, x=True, y=False)\n",
        "\n",
        "    # Block 2 (right node)\n",
        "\n",
        "    cru_right_3_2 = self.cru_9(cru_left_2_1, pooling=False)\n",
        "    class_right_3_2, map_right_3_2 = self.sfl_2(cru_right_3_2)\n",
        "\n",
        "    mask_right_3_2 = tf.where(projection_left_2_1 >= 0, x=True, y=False)\n",
        "\n",
        "    # Block 3 (left node)\n",
        "\n",
        "    cru_left_3_3 = self.cru_10(cru_right_2_2, pooling=False)\n",
        "    class_left_3_3, map_left_3_3 = self.sfl_3(cru_left_3_3)\n",
        "\n",
        "    mask_left_3_3 = tf.where(projection_right_2_2 < 0, x=True, y=False)\n",
        "\n",
        "    # Block 4 (right node)\n",
        "\n",
        "    cru_right_3_4 = self.cru_11(cru_right_2_2, pooling=False)\n",
        "    class_right_3_4, map_right_3_4 = self.sfl_4(cru_right_3_4)\n",
        "\n",
        "    mask_right_3_4 = tf.where(projection_right_2_2 >= 0, x=True, y=False)\n",
        "\n",
        "    # Block 5 (left node)\n",
        "\n",
        "    cru_left_3_5 = self.cru_12(cru_left_2_3, pooling=False)\n",
        "    class_left_3_5, map_left_3_5 = self.sfl_5(cru_left_3_5)\n",
        "\n",
        "    mask_left_3_5 = tf.where(projection_left_2_3 < 0, x=True, y=False)\n",
        "\n",
        "    # Block 6 (right node)\n",
        "\n",
        "    cru_right_3_6 = self.cru_13(cru_left_2_3, pooling=False)\n",
        "    class_right_3_6, map_right_3_6 = self.sfl_6(cru_right_3_6)\n",
        "\n",
        "    mask_right_3_6 = tf.where(projection_left_2_3 >= 0, x=True, y=False)\n",
        "\n",
        "    # Block 7 (left node)\n",
        "\n",
        "    cru_left_3_7 = self.cru_14(cru_right_2_4, pooling=False)\n",
        "    class_left_3_7, map_left_3_7 = self.sfl_7(cru_left_3_7)\n",
        "\n",
        "    mask_left_3_7 = tf.where(projection_right_2_4 < 0, x=True, y=False)\n",
        "\n",
        "    # Block 8 (right node)\n",
        "\n",
        "    cru_right_3_8 = self.cru_15(cru_right_2_4, pooling=False)\n",
        "    class_right_3_8, map_right_3_8 = self.sfl_8(cru_right_3_8)\n",
        "\n",
        "    mask_right_3_8 = tf.where(projection_right_2_4 >= 0, x=True, y=False)\n",
        "\n",
        "    # Outputs\n",
        "\n",
        "    classes_pred = [class_left_3_1, class_right_3_2, class_left_3_3, class_right_3_4,\n",
        "                    class_left_3_5, class_right_3_6, class_left_3_7, class_right_3_8]\n",
        "\n",
        "    maps_pred = [map_left_3_1, map_right_3_2, map_left_3_3, map_right_3_4,\n",
        "                  map_left_3_5, map_right_3_6, map_left_3_7, map_right_3_8]\n",
        "\n",
        "    unsupervised_loss = unsupervised_root_loss + unsupervised_left_1_1_loss + unsupervised_right_1_2_loss\n",
        "    unsupervised_loss += unsupervised_left_2_1_loss + unsupervised_right_2_2_loss + unsupervised_left_2_3_loss\n",
        "    unsupervised_loss += unsupervised_right_2_4_loss\n",
        "\n",
        "    masks = [mask_left_3_1, mask_right_3_2, mask_left_3_3, mask_right_3_4, \n",
        "              mask_left_3_5, mask_right_3_6, mask_left_3_7, mask_right_3_8]\n",
        "\n",
        "    if training:\n",
        "      return classes_pred, maps_pred, masks, unsupervised_loss\n",
        "    else:\n",
        "      return classes_pred, maps_pred, masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paH6_WRGMpzD",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkPEQ7nFvNv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DTN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoVyj7JXvHqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5)\n",
        "batch_size = 32\n",
        "epochs = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FPPvEzoMrGJ",
        "colab_type": "text"
      },
      "source": [
        "### Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbjgJCZyMv0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0LZZ6F2v0rk",
        "colab_type": "text"
      },
      "source": [
        "### Supervised Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PULoXoLwv9Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "L1_loss = tf.keras.losses.MeanAbsoluteError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjt-eGRJv86W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a1 = 0.001\n",
        "a2 = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yduDr1Jtv0K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_sfl_loss(labels, masks_true, classes_pred, masks_pred, masks):\n",
        "  total_loss = 0.0\n",
        "\n",
        "  for pred, mask_pred, mask in zip(classes_pred, masks_pred, masks):\n",
        "    data_in_node = tf.reduce_sum(tf.cast(mask, tf.float32))\n",
        "\n",
        "    if data_in_node > 0:\n",
        "      masked_labels = tf.boolean_mask(labels, tf.squeeze(mask))\n",
        "      masked_classes = tf.boolean_mask(pred, tf.squeeze(mask))\n",
        "      masked_mask = tf.boolean_mask(mask_pred, tf.squeeze(mask))\n",
        "\n",
        "      classification_loss = binary_cross_entropy(masked_labels, masked_classes)\n",
        "      mask_loss = L1_loss(masks_true, masks_pred)\n",
        "\n",
        "      total_loss += (a1 * classification_loss) + (a2 * mask_loss)\n",
        "\n",
        "  return total_loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGs52S5TxACX",
        "colab_type": "text"
      },
      "source": [
        "### Dummy data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxVPYlh5w_0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = np.random.randint(2, size=32)\n",
        "labels_batches = [label, label, label] # Simulates an array with 3 batches\n",
        "labels_batches = tf.cast(labels_batches, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izF37iPd4PEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_batches = tf.random.uniform([3, 32, 256, 256, 6], minval=0, maxval=255, dtype=tf.int64)\n",
        "images_batches = tf.cast(images_batches, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0b7BPds42Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "masks_batches = tf.random.uniform([3, 32, 32, 32, 1], minval=0, maxval=2, dtype=tf.int64)\n",
        "masks_batches = tf.cast(masks_batches, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDWVTDp4vlzh",
        "colab_type": "text"
      },
      "source": [
        "### Train functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3x3PhfJL2Dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels, masks_true, total_steps):\n",
        "  with tf.GradientTape() as tape:\n",
        "    classes_pred, maps_pred, masks, unsupervised_loss = model(images, labels, training=True)\n",
        "\n",
        "    supervised_loss = compute_sfl_loss(labels, masks_true, classes_pred, maps_pred, masks)\n",
        "\n",
        "    if total_steps > 10000:\n",
        "      loss = supervised_loss + unsupervised_loss\n",
        "    else:\n",
        "      loss = supervised_loss\n",
        "      \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_rTRNlqL8Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_results = []\n",
        "total_steps = 0\n",
        "train_steps = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3uBJfOVL10h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, total_steps):\n",
        "  for epoch in range(epochs):\n",
        "    batch_time = time.time()\n",
        "    epoch_time = time.time()\n",
        "    step = 0\n",
        "\n",
        "    epoch_count = f\"0{epoch + 1}/{epochs}\" if epoch < 9 else f\"{epoch + 1}/{epochs}\"\n",
        "\n",
        "    # Change for a true generator\n",
        "    for images, labels, masks_true in zip(images_batches, labels_batches, masks_batches):\n",
        "      loss = train_step(images, labels, masks_true, total_steps)\n",
        "\n",
        "      loss = float(loss.numpy())\n",
        "      step += 1\n",
        "\n",
        "      print('\\r', 'Epoch', epoch_count, '| Step', f\"{step}/{train_steps}\",\n",
        "            '| loss:', f\"{loss:.5f}\", \"| Step time:\", f\"{time.time() - batch_time:.2f}\", end='')    \n",
        "      \n",
        "      batch_time = time.time()\n",
        "      total_steps += 1\n",
        "\n",
        "    loss_results.append(loss)\n",
        "\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print('\\r', 'Epoch', epoch_count, '| Step', f\"{step}/{train_steps}\",\n",
        "          '| loss:', \"| Epoch time:\", f\"{time.time() - epoch_time:.2f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QER5RQhLA5aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(epochs, total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anN41xYq-4Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}